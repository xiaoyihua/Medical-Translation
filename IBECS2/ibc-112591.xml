<?xml version="1.0" encoding="UTF-8" standalone="no"?>
<ibecs-document>
<record>
<header>
<identifier>ibc-112591</identifier>
<setSpec>1576-5962</setSpec>
</header>
<metadata xmlns="http://example.org/myapp/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:dcterms="http://purl.org/dc/terms/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://example.org/myapp/schema.xsd">
<dc:title xml:lang="en">Trade-offs between assessor team size and assessor expertise in affecting rating accuracy in assessment centers</dc:title>
<dc:description xml:lang="en">We investigated the effects of assessor team size on the accuracy of ratings in a presentation exercise as it is commonly used in assessment centers and compared it to the effects of two factors related to assessor expertise (assessor training and assessor background). On the basis of actual ratings from a simulated selection setting (N = 383), we sampled assessor teams of different sizes and with different expertise and determined the accuracy of their ratings in the presentation exercise. Of the three factors, assessor training had the strongest effect on rating accuracy. Furthermore, in most conditions, using larger assessor teams also led to more accurate ratings. In addition, the use of larger assessor teams compensated for having not attended an assessor training only when the assessors had a psychological background. Concerning assessor background, we did not find a significant main effect. Practical implications and directions for future research are discussed(AU)</dc:description>
<dc:creator>Melchers, Klaus G</dc:creator>
<dc:creator>Corte, Wilfried de</dc:creator>
<dc:creator>Wirz, Andreja</dc:creator>
<dc:creator>Lievens, Filip</dc:creator>
<dc:creator>Kleinmann, Martin</dc:creator>
<dc:language>en</dc:language>
<dc:description xml:lang="es">Investigamos los efectos del tamaño del equipo evaluador sobre la precisión de las valoraciones en un ejercicio de presentación tal como es habitualmente utilizado en los AC y lo comparamos con los efectos de dos factores relacionados con la pericia del evaluador (entrenamiento e historial). Sobre las valoraciones en una situación simulada de selección (N = 383), muestreamos equipos de evaluadores de diferente tamaño y con diferente pericia y determinamos la precisión de sus valoraciones en el ejercicio de presentación. De los tres factores, el entrenamiento de evaluadores tuvo el efecto más fuerte sobre la precisión de la valoración. Además, en la mayoría de las condiciones, usar equipos con mayor número de evaluador también da lugar a valoraciones más precisas. También, el uso de equipos mayores compensó la falta de asistencia de un valorador al entrenamiento cuando los evaluadores tenían formación psicológica. En relación con esto último, no encontramos un efecto principal significativo. Se comentan las implicaciones para la práctica y la investigación futura(AU)</dc:description>
<dc:source>Rev. psicol. trab. organ. (1999);29(1): 13-20, ene.-abr. 2013. tab, ilus</dc:source>
<dc:identifier>ibc-112591</dc:identifier>
<dc:title xml:lang="es">Trade-offs entre tamaño del equipo evaluador y pericia del evaluador y su efecto sobre la precisión de la valoración en los assessment centers</dc:title>
<dc:subject>^d28620</dc:subject>
<dc:subject>^d7756</dc:subject>
<dc:subject>^d15335^s22056</dc:subject>
<dc:subject>^d21034</dc:subject>
<dc:subject>^d15335^s22066</dc:subject>
<dc:subject>^d51780^s22045</dc:subject>
<dc:subject>^d21030</dc:subject>
<dc:subject>^d21044</dc:subject>
<dc:subject>^d15338^s22056</dc:subject>
<dc:subject>^d16048</dc:subject>
<dc:subject>^d15336</dc:subject>
<dc:subject>^d15339</dc:subject>
<dc:subject>^d9809^s22083</dc:subject>
<dc:subject>^d12031^s22066</dc:subject>
<dc:subject>^d12031^s22045</dc:subject>
<dc:type>article</dc:type>
<dc:date>201304</dc:date>
</metadata>
</record>
</ibecs-document>
